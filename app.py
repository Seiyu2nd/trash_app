import streamlit as st
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
from tensorflow.keras.utils import image_dataset_from_directory
from PIL import Image
import os
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import urllib.request
import zipfile
import pathlib

# ===== æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š =====
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«ãƒ•ã‚©ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ãï¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†
font_filename = "ipaexg.ttf"
if not os.path.isfile(font_filename):
    url = "https://moji.or.jp/wp-content/ipafont/IPAexfont/IPAexfont00401.zip"
    urllib.request.urlretrieve(url, "IPAexfont.zip")
    with zipfile.ZipFile("IPAexfont.zip", "r") as z:
        z.extractall(".")
    os.rename("IPAexfont00401/ipaexg.ttf", font_filename)

font_path = pathlib.Path(font_filename).resolve()
jp_prop = fm.FontProperties(fname=str(font_path))
# ãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²
fm.fontManager.addfont(str(font_path))
plt.rcParams['font.family'] = jp_prop.get_name()
plt.rcParams['axes.unicode_minus'] = False  # ãƒã‚¤ãƒŠã‚¹è¨˜å·ãŒâ–¡ã«ãªã‚‹ã®ã‚’å›é¿

# ===== è¨­å®š =====
TRAIN_DIR = "train"
MODEL_PATH = os.path.join(os.path.dirname(__file__), "final_trash_model.h5")

# ===== ã‚¿ã‚¤ãƒˆãƒ« =====
st.title("â™»ï¸ ã”ã¿åˆ†é¡AI")
st.write("ï¼ˆä¹¾é›»æ± ãƒ»ã‚¹ãƒ—ãƒ¬ãƒ¼ç¼¶ãƒ»ãƒ©ã‚¤ã‚¿ãƒ¼ï¼‰")
st.write("ã‚«ãƒ¡ãƒ©ã¾ãŸã¯ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åˆ†é¡ã‚’è¡Œã„ã¾ã™ã€‚")

# ===== ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¯ãƒ©ã‚¹èª­ã¿è¾¼ã¿ =====
@st.cache_resource
def load_trash_model():
    if not os.path.exists(MODEL_PATH):
        st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MODEL_PATH}")
        st.stop()
    model = load_model(MODEL_PATH)
    dataset = image_dataset_from_directory(TRAIN_DIR, image_size=(224, 224), shuffle=False)
    class_names = dataset.class_names
    return model, class_names

model, class_names = load_trash_model()
jp_labels = {"battery": "ä¹¾é›»æ± ", "spray": "ã‚¹ãƒ—ãƒ¬ãƒ¼ç¼¶", "lighter": "ãƒ©ã‚¤ã‚¿ãƒ¼"}

# ===== å…¥åŠ›æ–¹æ³• =====
option = st.radio("ç”»åƒã®å–å¾—æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„", ["ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“¸ ã‚«ãƒ¡ãƒ©ã§æ’®å½±"])
uploaded_image = None
if option == "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    uploaded_image = st.file_uploader("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„", type=["jpg", "jpeg", "png"])
elif option == "ğŸ“¸ ã‚«ãƒ¡ãƒ©ã§æ’®å½±":
    camera_photo = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±")
    if camera_photo is not None:
        uploaded_image = camera_photo

# ===== æ¨è«–å‡¦ç† =====
if uploaded_image is not None:
    st.image(uploaded_image, caption="å…¥åŠ›ç”»åƒ", use_container_width=True)
    img = Image.open(uploaded_image).convert("RGB").resize((224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0) / 255.0
    pred = model.predict(x)
    predicted_class = class_names[np.argmax(pred)]
    confidence = np.max(pred)
    label_jp = jp_labels.get(predicted_class, predicted_class)
    st.success(f"### åˆ¤å®šçµæœ: **{label_jp}**ï¼ˆç¢ºä¿¡åº¦ {confidence*100:.2f}%ï¼‰")

    st.subheader("ğŸ“Š å„ã‚¯ãƒ©ã‚¹ã®äºˆæ¸¬ç¢ºç‡")
    probs = pred[0]
    jp_class_names = [jp_labels.get(c, c) for c in class_names]

    fig, ax = plt.subplots()
    ax.barh(jp_class_names, probs, color='skyblue')
    ax.set_xlim(0, 1)
    ax.set_xlabel("ç¢ºç‡", fontproperties=jp_prop)
    ax.set_title("åˆ†é¡ç¢ºç‡", fontproperties=jp_prop)
    for i, v in enumerate(probs):
        ax.text(v + 0.02, i, f"{v*100:.1f}%", va='center', fontproperties=jp_prop)
    st.pyplot(fig)
else:
    st.info("ğŸ“· ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚«ãƒ¡ãƒ©ã§æ’®å½±ã—ã¦ãã ã•ã„ã€‚")
